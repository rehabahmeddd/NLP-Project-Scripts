{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbfb9cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:21:47.305780Z",
     "iopub.status.busy": "2025-12-14T00:21:47.305511Z",
     "iopub.status.idle": "2025-12-14T00:21:52.639439Z",
     "shell.execute_reply": "2025-12-14T00:21:52.638691Z"
    },
    "papermill": {
     "duration": 5.347798,
     "end_time": "2025-12-14T00:21:52.640901",
     "exception": false,
     "start_time": "2025-12-14T00:21:47.293103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.*\r\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\r\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: protobuf\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 6.33.0\r\n",
      "    Uninstalling protobuf-6.33.0:\r\n",
      "      Successfully uninstalled protobuf-6.33.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "a2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.20.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f02d70c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:21:52.666938Z",
     "iopub.status.busy": "2025-12-14T00:21:52.666622Z",
     "iopub.status.idle": "2025-12-14T00:21:56.233125Z",
     "shell.execute_reply": "2025-12-14T00:21:56.231953Z"
    },
    "papermill": {
     "duration": 3.581042,
     "end_time": "2025-12-14T00:21:56.234931",
     "exception": false,
     "start_time": "2025-12-14T00:21:52.653889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-crf\r\n",
      "  Downloading pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\r\n",
      "Installing collected packages: pytorch-crf\r\n",
      "Successfully installed pytorch-crf-0.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-crf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae7dd6",
   "metadata": {},
   "source": [
    "## AraBert Model (last 2 layers unfrozen) + BiLSTM(3 Layers) + CRF ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0e6ea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:21:56.261644Z",
     "iopub.status.busy": "2025-12-14T00:21:56.260850Z",
     "iopub.status.idle": "2025-12-14T00:22:09.990159Z",
     "shell.execute_reply": "2025-12-14T00:22:09.989172Z"
    },
    "papermill": {
     "duration": 13.744175,
     "end_time": "2025-12-14T00:22:09.991419",
     "exception": false,
     "start_time": "2025-12-14T00:21:56.247244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Imports & configuration\n",
    "\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "TRAIN_PATH = \"/kaggle/input/dataset1/train.txt\"\n",
    "VAL_PATH = \"/kaggle/input/dataset1/val.txt\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdbbed6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:22:10.018091Z",
     "iopub.status.busy": "2025-12-14T00:22:10.017370Z",
     "iopub.status.idle": "2025-12-14T00:22:10.024685Z",
     "shell.execute_reply": "2025-12-14T00:22:10.023845Z"
    },
    "papermill": {
     "duration": 0.021267,
     "end_time": "2025-12-14T00:22:10.025876",
     "exception": false,
     "start_time": "2025-12-14T00:22:10.004609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linguistic features defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Arabic diacritics & text utilities\n",
    "\n",
    "ARABIC_DIACRITICS = set([\n",
    "    \"\\u064b\",  # Fathatan\n",
    "    \"\\u064c\",  # Dammatan\n",
    "    \"\\u064d\",  # Kasratan\n",
    "    \"\\u064e\",  # Fatha\n",
    "    \"\\u064f\",  # Damma\n",
    "    \"\\u0650\",  # Kasra\n",
    "    \"\\u0651\",  # Shadda\n",
    "    \"\\u0652\",  # Sukun\n",
    "    \"\\u0670\",  # Superscript Alef\n",
    "])\n",
    "\n",
    "def is_diacritic(ch: str) -> bool:\n",
    "    return ch in ARABIC_DIACRITICS\n",
    "\n",
    "def is_arabic_letter(ch: str) -> bool:\n",
    "    if not (\"\\u0600\" <= ch <= \"\\u06FF\" or \"\\u0750\" <= ch <= \"\\u077F\"):\n",
    "        return False\n",
    "    if is_diacritic(ch):\n",
    "        return False\n",
    "    cat = unicodedata.category(ch)\n",
    "    return cat.startswith(\"L\")\n",
    "\n",
    "def strip_diacritics(text: str) -> str:\n",
    "    return \"\".join(ch for ch in text if not is_diacritic(ch))\n",
    "\n",
    "# Arabic linguistic categories\n",
    "SUN_LETTERS = set(\"تثدذرزسشصضطظنل\")\n",
    "MOON_LETTERS = set(\"ءأإابجحخعغفقكمهوي\")\n",
    "\n",
    "# Common prefixes and suffixes\n",
    "ARABIC_PREFIXES = set(\"وفبكلس\")  # wa, fa, bi, ka, li, sa\n",
    "ARABIC_SUFFIXES = set(\"هاكني\")   # ha, ka, ni, ya (pronoun suffixes)\n",
    "\n",
    "# Special characters\n",
    "ALEF_VARIANTS = set(\"اأإآى\")\n",
    "WAW_YA = set(\"وي\")\n",
    "TA_MARBUTA = \"ة\"\n",
    "ALEF_MAQSURA = \"ى\"\n",
    "HAMZA_VARIANTS = set(\"ءأإؤئ\")\n",
    "\n",
    "print(\"Linguistic features defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a50fe419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:22:10.053534Z",
     "iopub.status.busy": "2025-12-14T00:22:10.053216Z",
     "iopub.status.idle": "2025-12-14T00:22:10.060276Z",
     "shell.execute_reply": "2025-12-14T00:22:10.059433Z"
    },
    "papermill": {
     "duration": 0.022622,
     "end_time": "2025-12-14T00:22:10.061663",
     "exception": false,
     "start_time": "2025-12-14T00:22:10.039041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4: Parse line with diacritic normalization\n",
    "\n",
    "def normalize_shadda_order(diacritics: List[str]) -> str:\n",
    "    \"\"\"Normalize: Shadda always comes first in combo.\"\"\"\n",
    "    if not diacritics:\n",
    "        return \"\"\n",
    "    shadda = \"\\u0651\"\n",
    "    has_shadda = shadda in diacritics\n",
    "    others = [d for d in diacritics if d != shadda]\n",
    "    if has_shadda:\n",
    "        return shadda + \"\".join(others)\n",
    "    return \"\".join(others)\n",
    "\n",
    "def process_line_to_bases_and_labels(line: str) -> Tuple[List[str], List[str]]:\n",
    "    line = line.rstrip(\"\\n\")\n",
    "    base_chars: List[str] = []\n",
    "    label_combos: List[str] = []\n",
    "\n",
    "    current_base = None\n",
    "    current_diacritics: List[str] = []\n",
    "\n",
    "    for ch in line:\n",
    "        if is_diacritic(ch):\n",
    "            if current_base is not None:\n",
    "                current_diacritics.append(ch)\n",
    "        else:\n",
    "            if current_base is not None:\n",
    "                combo = normalize_shadda_order(current_diacritics)\n",
    "                label_combos.append(combo)\n",
    "                base_chars.append(current_base)\n",
    "            current_base = ch\n",
    "            current_diacritics = []\n",
    "\n",
    "    if current_base is not None:\n",
    "        combo = normalize_shadda_order(current_diacritics)\n",
    "        label_combos.append(combo)\n",
    "        base_chars.append(current_base)\n",
    "\n",
    "    return base_chars, label_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f3c13c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:22:10.086128Z",
     "iopub.status.busy": "2025-12-14T00:22:10.085775Z",
     "iopub.status.idle": "2025-12-14T00:22:16.713423Z",
     "shell.execute_reply": "2025-12-14T00:22:16.712267Z"
    },
    "papermill": {
     "duration": 6.64124,
     "end_time": "2025-12-14T00:22:16.714761",
     "exception": false,
     "start_time": "2025-12-14T00:22:10.073521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label set:\n",
      "  0: 'NONE'\n",
      "  1: 'ً'\n",
      "  2: 'ٌ'\n",
      "  3: 'ٍ'\n",
      "  4: 'َ'\n",
      "  5: 'ُ'\n",
      "  6: 'ِ'\n",
      "  7: 'ّ'\n",
      "  8: 'ًّ'\n",
      "  9: 'ٌّ'\n",
      "  10: 'ٍّ'\n",
      "  11: 'َّ'\n",
      "  12: 'ُّ'\n",
      "  13: 'ِّ'\n",
      "  14: 'ْ'\n",
      "\n",
      "NUM_LABELS = 15\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Build label vocabulary\n",
    "\n",
    "def build_label_vocab(path: str) -> Dict[str, int]:\n",
    "    combos = set()\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            _, labels = process_line_to_bases_and_labels(line)\n",
    "            combos.update(labels)\n",
    "\n",
    "    normalized = set()\n",
    "    for c in combos:\n",
    "        normalized.add(\"NONE\" if c == \"\" else c)\n",
    "\n",
    "    sorted_labels = sorted(normalized, key=lambda x: (x != \"NONE\", x))\n",
    "    label2id = {lab: i for i, lab in enumerate(sorted_labels)}\n",
    "\n",
    "    print(\"Label set:\")\n",
    "    for i, lab in enumerate(sorted_labels):\n",
    "        print(f\"  {i}: {repr(lab)}\")\n",
    "    return label2id\n",
    "\n",
    "label2id = build_label_vocab(TRAIN_PATH)\n",
    "id2label = {i: lab for lab, i in label2id.items()}\n",
    "NUM_LABELS = len(label2id)\n",
    "print(f\"\\nNUM_LABELS = {NUM_LABELS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "646a9faa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:22:16.741282Z",
     "iopub.status.busy": "2025-12-14T00:22:16.740601Z",
     "iopub.status.idle": "2025-12-14T00:22:23.207407Z",
     "shell.execute_reply": "2025-12-14T00:22:23.206467Z"
    },
    "papermill": {
     "duration": 6.48088,
     "end_time": "2025-12-14T00:22:23.208757",
     "exception": false,
     "start_time": "2025-12-14T00:22:16.727877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 74\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Character vocabulary\n",
    "\n",
    "SPECIAL_TOKENS = [\"<PAD>\", \"<UNK>\"]\n",
    "\n",
    "def build_char_vocab(path: str) -> Dict[str, int]:\n",
    "    chars = set()\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            base_chars, _ = process_line_to_bases_and_labels(line)\n",
    "            chars.update(base_chars)\n",
    "\n",
    "    sorted_chars = sorted(chars)\n",
    "    vocab = {tok: i for i, tok in enumerate(SPECIAL_TOKENS)}\n",
    "    for ch in sorted_chars:\n",
    "        if ch not in vocab:\n",
    "            vocab[ch] = len(vocab)\n",
    "\n",
    "    print(f\"Vocab size: {len(vocab)}\")\n",
    "    return vocab\n",
    "\n",
    "char2id = build_char_vocab(TRAIN_PATH)\n",
    "id2char = {i: ch for ch, i in char2id.items()}\n",
    "VOCAB_SIZE = len(char2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ab0fe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:22:23.235151Z",
     "iopub.status.busy": "2025-12-14T00:22:23.234636Z",
     "iopub.status.idle": "2025-12-14T00:22:23.239742Z",
     "shell.execute_reply": "2025-12-14T00:22:23.239019Z"
    },
    "papermill": {
     "duration": 0.019567,
     "end_time": "2025-12-14T00:22:23.240885",
     "exception": false,
     "start_time": "2025-12-14T00:22:23.221318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 7: Line structure with word boundaries\n",
    "\n",
    "def line_to_struct(line: str):\n",
    "    base_chars, combos = process_line_to_bases_and_labels(line)\n",
    "    plain_text = \"\".join(base_chars)\n",
    "    words = plain_text.split()\n",
    "\n",
    "    char2word = []\n",
    "    current_word_idx = -1\n",
    "    inside_word = False\n",
    "\n",
    "    for ch in plain_text:\n",
    "        if ch.isspace():\n",
    "            char2word.append(-1)\n",
    "            if inside_word:\n",
    "                inside_word = False\n",
    "        else:\n",
    "            if not inside_word:\n",
    "                inside_word = True\n",
    "                current_word_idx += 1\n",
    "            char2word.append(current_word_idx)\n",
    "\n",
    "    return base_chars, combos, plain_text, words, char2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7bda822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:22:23.266307Z",
     "iopub.status.busy": "2025-12-14T00:22:23.265947Z",
     "iopub.status.idle": "2025-12-14T00:22:23.280768Z",
     "shell.execute_reply": "2025-12-14T00:22:23.279760Z"
    },
    "papermill": {
     "duration": 0.02923,
     "end_time": "2025-12-14T00:22:23.282075",
     "exception": false,
     "start_time": "2025-12-14T00:22:23.252845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features per char: 24\n",
      "Total chars: 6\n",
      "Feature extraction test passed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Enhanced linguistic feature extraction - 24 features per character\n",
    "\n",
    "def extract_enhanced_features(plain_text: str, char2word: List[int], words: List[str]) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Extract 24 linguistic features per character.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    n = len(plain_text)\n",
    "    \n",
    "    # Precompute word info\n",
    "    word_starts = set()\n",
    "    word_ends = set()\n",
    "    pos = 0\n",
    "    for word in words:\n",
    "        word_starts.add(pos)\n",
    "        word_ends.add(pos + len(word) - 1)\n",
    "        pos += len(word) + 1  # +1 for space\n",
    "    \n",
    "    for i, ch in enumerate(plain_text):\n",
    "        f = []\n",
    "        \n",
    "        # === Basic type features (4) ===\n",
    "        f.append(1.0 if is_arabic_letter(ch) else 0.0)\n",
    "        f.append(1.0 if ch.isspace() else 0.0)\n",
    "        f.append(1.0 if ch.isdigit() else 0.0)\n",
    "        f.append(1.0 if unicodedata.category(ch).startswith(\"P\") else 0.0)\n",
    "        \n",
    "        # === Arabic letter categories (6) ===\n",
    "        f.append(1.0 if ch in SUN_LETTERS else 0.0)\n",
    "        f.append(1.0 if ch in MOON_LETTERS else 0.0)\n",
    "        f.append(1.0 if ch in ALEF_VARIANTS else 0.0)\n",
    "        f.append(1.0 if ch in HAMZA_VARIANTS else 0.0)\n",
    "        f.append(1.0 if ch in WAW_YA else 0.0)\n",
    "        f.append(1.0 if ch == TA_MARBUTA else 0.0)\n",
    "        \n",
    "        # === Position in word (4) ===\n",
    "        is_word_start = i in word_starts\n",
    "        is_word_end = i in word_ends\n",
    "        f.append(1.0 if is_word_start else 0.0)\n",
    "        f.append(1.0 if is_word_end else 0.0)\n",
    "        f.append(1.0 if is_word_start and is_word_end else 0.0)  # Single char word\n",
    "        \n",
    "        # Relative position in word\n",
    "        w_idx = char2word[i] if i < len(char2word) else -1\n",
    "        if w_idx >= 0 and w_idx < len(words):\n",
    "            word_len = len(words[w_idx])\n",
    "            # Find position within word\n",
    "            word_start_pos = sum(len(words[j]) + 1 for j in range(w_idx))\n",
    "            pos_in_word = i - word_start_pos\n",
    "            f.append(pos_in_word / max(word_len - 1, 1) if word_len > 1 else 0.5)\n",
    "        else:\n",
    "            f.append(0.0)\n",
    "        \n",
    "        # === Morphological hints (5) ===\n",
    "        # Prefix character (beginning of word)\n",
    "        f.append(1.0 if is_word_start and ch in ARABIC_PREFIXES else 0.0)\n",
    "        # Suffix character (end of word)\n",
    "        f.append(1.0 if is_word_end and ch in ARABIC_SUFFIXES else 0.0)\n",
    "        \n",
    "        # Definite article detection (ال)\n",
    "        is_alef_lam = False\n",
    "        if is_word_start and ch == 'ا' and i + 1 < n and plain_text[i + 1] == 'ل':\n",
    "            is_alef_lam = True\n",
    "        if i > 0 and plain_text[i - 1] == 'ا' and ch == 'ل' and (i - 1) in word_starts:\n",
    "            is_alef_lam = True\n",
    "        f.append(1.0 if is_alef_lam else 0.0)\n",
    "        \n",
    "        # After definite article (sun letter assimilation context)\n",
    "        after_al = False\n",
    "        if i >= 2 and w_idx >= 0:\n",
    "            word_start_pos = sum(len(words[j]) + 1 for j in range(w_idx))\n",
    "            if i - word_start_pos == 2:  # Third char in word\n",
    "                if plain_text[word_start_pos:word_start_pos+2] == \"ال\":\n",
    "                    after_al = True\n",
    "        f.append(1.0 if after_al else 0.0)\n",
    "        \n",
    "        # Ta Marbuta at word end (almost always Fatha)\n",
    "        f.append(1.0 if ch == TA_MARBUTA and is_word_end else 0.0)\n",
    "        \n",
    "        # === Context features (5) ===\n",
    "        # Previous character type\n",
    "        prev_ch = plain_text[i - 1] if i > 0 else ' '\n",
    "        f.append(1.0 if is_arabic_letter(prev_ch) else 0.0)\n",
    "        f.append(1.0 if prev_ch in ALEF_VARIANTS else 0.0)\n",
    "        \n",
    "        # Next character type\n",
    "        next_ch = plain_text[i + 1] if i + 1 < n else ' '\n",
    "        f.append(1.0 if is_arabic_letter(next_ch) else 0.0)\n",
    "        f.append(1.0 if next_ch.isspace() or i + 1 >= n else 0.0)  # Before space/end\n",
    "        f.append(1.0 if next_ch == TA_MARBUTA else 0.0)\n",
    "        \n",
    "        features.append(f)\n",
    "    \n",
    "    return features\n",
    "\n",
    "NUM_ENHANCED_FEATURES = 24\n",
    "\n",
    "# Test\n",
    "test_text = \"الكتاب\"\n",
    "test_base, _, test_plain, test_words, test_c2w = line_to_struct(test_text)\n",
    "test_feats = extract_enhanced_features(test_plain, test_c2w, test_words)\n",
    "print(f\"Features per char: {len(test_feats[0])}\")\n",
    "print(f\"Total chars: {len(test_feats)}\")\n",
    "assert len(test_feats[0]) == NUM_ENHANCED_FEATURES, f\"Expected {NUM_ENHANCED_FEATURES}, got {len(test_feats[0])}\"\n",
    "print(\"Feature extraction test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "161dd61e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:22:23.307017Z",
     "iopub.status.busy": "2025-12-14T00:22:23.306735Z",
     "iopub.status.idle": "2025-12-14T00:22:23.314348Z",
     "shell.execute_reply": "2025-12-14T00:22:23.313413Z"
    },
    "papermill": {
     "duration": 0.021839,
     "end_time": "2025-12-14T00:22:23.315589",
     "exception": false,
     "start_time": "2025-12-14T00:22:23.293750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced dataset class defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Dataset with enhanced features\n",
    "\n",
    "class EnhancedDiacritizationDataset(Dataset):\n",
    "    def __init__(self, path: str, char2id: Dict[str, int], label2id: Dict[str, int]):\n",
    "        self.samples = []\n",
    "        self.char2id = char2id\n",
    "        self.label2id = label2id\n",
    "\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "\n",
    "                base_chars, combos, plain_text, words, char2word = line_to_struct(line)\n",
    "                \n",
    "                # Labels\n",
    "                multi_labels = []\n",
    "                binary_labels = []\n",
    "                mask = []\n",
    "                for ch, combo in zip(base_chars, combos):\n",
    "                    lab_name = \"NONE\" if combo == \"\" else combo\n",
    "                    if lab_name not in self.label2id:\n",
    "                        lab_name = \"NONE\"\n",
    "                    lab_id = self.label2id[lab_name]\n",
    "                    multi_labels.append(lab_id)\n",
    "                    binary_labels.append(0 if lab_name == \"NONE\" else 1)\n",
    "                    mask.append(1 if is_arabic_letter(ch) else 0)\n",
    "\n",
    "                char_ids = [self.char2id.get(ch, self.char2id[\"<UNK>\"]) for ch in base_chars]\n",
    "                \n",
    "                # Enhanced features\n",
    "                enhanced_feats = extract_enhanced_features(plain_text, char2word, words)\n",
    "\n",
    "                self.samples.append({\n",
    "                    \"char_ids\": char_ids,\n",
    "                    \"multi_labels\": multi_labels,\n",
    "                    \"binary_labels\": binary_labels,\n",
    "                    \"mask\": mask,\n",
    "                    \"plain_text\": plain_text,\n",
    "                    \"words\": words,\n",
    "                    \"char2word\": char2word,\n",
    "                    \"enhanced_feats\": enhanced_feats,\n",
    "                })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "print(\"Enhanced dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c270c21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:22:23.341485Z",
     "iopub.status.busy": "2025-12-14T00:22:23.341168Z",
     "iopub.status.idle": "2025-12-14T00:22:23.349281Z",
     "shell.execute_reply": "2025-12-14T00:22:23.348467Z"
    },
    "papermill": {
     "duration": 0.023137,
     "end_time": "2025-12-14T00:22:23.350568",
     "exception": false,
     "start_time": "2025-12-14T00:22:23.327431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 10: Collate function with enhanced features\n",
    "\n",
    "def collate_fn_enhanced(batch):\n",
    "    max_len = max(len(sample[\"char_ids\"]) for sample in batch)\n",
    "    pad_id = char2id[\"<PAD>\"]\n",
    "\n",
    "    batch_char_ids = []\n",
    "    batch_multi = []\n",
    "    batch_binary = []\n",
    "    batch_mask = []\n",
    "    batch_plain_text = []\n",
    "    batch_words = []\n",
    "    batch_char2word = []\n",
    "    batch_enhanced_feats = []\n",
    "\n",
    "    for sample in batch:\n",
    "        L = len(sample[\"char_ids\"])\n",
    "        pad_len = max_len - L\n",
    "\n",
    "        batch_char_ids.append(sample[\"char_ids\"] + [pad_id] * pad_len)\n",
    "        batch_multi.append(sample[\"multi_labels\"] + [0] * pad_len)\n",
    "        batch_binary.append(sample[\"binary_labels\"] + [0] * pad_len)\n",
    "        \n",
    "        # Mask: 1 for Arabic letters only (for evaluation)\n",
    "        # Don't force first position - use actual Arabic letter mask\n",
    "        mask = sample[\"mask\"] + [0] * pad_len\n",
    "        batch_mask.append(mask)\n",
    "        \n",
    "        batch_char2word.append(sample[\"char2word\"] + [-1] * pad_len)\n",
    "\n",
    "        batch_plain_text.append(sample[\"plain_text\"])\n",
    "        batch_words.append(sample[\"words\"])\n",
    "        \n",
    "        # Pad enhanced features\n",
    "        feats = sample[\"enhanced_feats\"]\n",
    "        zero_feat = [0.0] * NUM_ENHANCED_FEATURES\n",
    "        padded_feats = feats + [zero_feat] * pad_len\n",
    "        batch_enhanced_feats.append(padded_feats)\n",
    "\n",
    "    return {\n",
    "        \"char_ids\": torch.tensor(batch_char_ids, dtype=torch.long),\n",
    "        \"multi_labels\": torch.tensor(batch_multi, dtype=torch.long),\n",
    "        \"binary_labels\": torch.tensor(batch_binary, dtype=torch.float32),\n",
    "        \"mask\": torch.tensor(batch_mask, dtype=torch.float32),\n",
    "        \"plain_text\": batch_plain_text,\n",
    "        \"words\": batch_words,\n",
    "        \"char2word\": torch.tensor(batch_char2word, dtype=torch.long),\n",
    "        \"enhanced_feats\": torch.tensor(batch_enhanced_feats, dtype=torch.float32),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd457c6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:22:23.379682Z",
     "iopub.status.busy": "2025-12-14T00:22:23.379051Z",
     "iopub.status.idle": "2025-12-14T00:24:31.358159Z",
     "shell.execute_reply": "2025-12-14T00:24:31.357179Z"
    },
    "papermill": {
     "duration": 128.008109,
     "end_time": "2025-12-14T00:24:31.372611",
     "exception": false,
     "start_time": "2025-12-14T00:22:23.364502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train: 50,000 samples, 2,084 batches\n",
      "Val: 2,500 samples, 105 batches\n",
      "\n",
      "Batch shapes:\n",
      "  char_ids: torch.Size([24, 704])\n",
      "  enhanced_feats: torch.Size([24, 704, 24])\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Create datasets and loaders\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "train_dataset = EnhancedDiacritizationDataset(TRAIN_PATH, char2id, label2id)\n",
    "val_dataset = EnhancedDiacritizationDataset(VAL_PATH, char2id, label2id)\n",
    "\n",
    "BATCH_SIZE = 24\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_enhanced)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn_enhanced)\n",
    "\n",
    "print(f\"Train: {len(train_dataset):,} samples, {len(train_loader):,} batches\")\n",
    "print(f\"Val: {len(val_dataset):,} samples, {len(val_loader):,} batches\")\n",
    "\n",
    "# Test one batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"\\nBatch shapes:\")\n",
    "print(f\"  char_ids: {sample_batch['char_ids'].shape}\")\n",
    "print(f\"  enhanced_feats: {sample_batch['enhanced_feats'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c69cde25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:24:31.399698Z",
     "iopub.status.busy": "2025-12-14T00:24:31.399224Z",
     "iopub.status.idle": "2025-12-14T00:25:02.611487Z",
     "shell.execute_reply": "2025-12-14T00:25:02.610600Z"
    },
    "papermill": {
     "duration": 31.227308,
     "end_time": "2025-12-14T00:25:02.612693",
     "exception": false,
     "start_time": "2025-12-14T00:24:31.385385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading aubmindlab/bert-base-arabertv02...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b629c1db00094c5bbf866f5a52b4c02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/381 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e58a18e89e941c08dc73b542267d266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609fad74c1f8410292ae45fd8ca99c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb30f157cf334857abd85d996f798106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a536160efc7468e801281cd18a6754f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2025-12-14 00:24:42.686507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765671882.885899      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765671882.943498      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ffee0d12f646cfa23f4916d348ba6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT hidden size: 768\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Load AraBERT\n",
    "\n",
    "BERT_MODEL_NAME = \"aubmindlab/bert-base-arabertv02\"\n",
    "\n",
    "print(f\"Loading {BERT_MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "bert_model = AutoModel.from_pretrained(BERT_MODEL_NAME)\n",
    "print(f\"BERT hidden size: {bert_model.config.hidden_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02fe3f05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:25:02.638925Z",
     "iopub.status.busy": "2025-12-14T00:25:02.638429Z",
     "iopub.status.idle": "2025-12-14T00:25:03.106519Z",
     "shell.execute_reply": "2025-12-14T00:25:03.105793Z"
    },
    "papermill": {
     "duration": 0.48238,
     "end_time": "2025-12-14T00:25:03.107657",
     "exception": false,
     "start_time": "2025-12-14T00:25:02.625277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 140,954,327\n",
      "CRF enabled: True\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Enhanced model with CRF integration\n",
    "\n",
    "from torchcrf import CRF\n",
    "\n",
    "class EnhancedDiacritizer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert_model,\n",
    "                 vocab_size: int,\n",
    "                 num_labels: int,\n",
    "                 num_enhanced_feats: int = 24,\n",
    "                 emb_dim: int = 64,\n",
    "                 feat_hidden_dim: int = 48,  # Larger to handle 24 features\n",
    "                 lstm_hidden_dim: int = 256,\n",
    "                 lstm_layers: int = 3,  # Deeper LSTM\n",
    "                 dropout: float = 0.3,\n",
    "                 freeze_bert: bool = True,\n",
    "                 use_crf: bool = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = bert_model\n",
    "        if freeze_bert:\n",
    "            for p in self.bert.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        self.bert_hidden_size = self.bert.config.hidden_size\n",
    "        self.use_crf = use_crf\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        # Character embedding\n",
    "        self.char_emb = nn.Embedding(vocab_size, emb_dim, padding_idx=char2id[\"<PAD>\"])\n",
    "\n",
    "        # Enhanced feature projection with more capacity\n",
    "        self.feat_proj = nn.Sequential(\n",
    "            nn.Linear(num_enhanced_feats, feat_hidden_dim),\n",
    "            nn.LayerNorm(feat_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            nn.Linear(feat_hidden_dim, feat_hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Input dimension\n",
    "        input_dim = emb_dim + feat_hidden_dim + self.bert_hidden_size\n",
    "\n",
    "        # Deeper BiLSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim,\n",
    "            lstm_hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.lstm_norm = nn.LayerNorm(lstm_hidden_dim * 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Output heads with CRF\n",
    "        self.binary_head = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden_dim * 2, lstm_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            nn.Linear(lstm_hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "        self.multi_head = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden_dim * 2, lstm_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            nn.Linear(lstm_hidden_dim, num_labels)\n",
    "        )\n",
    "        \n",
    "        # CRF layers\n",
    "        if use_crf:\n",
    "            self.crf_multi = CRF(num_labels, batch_first=True)\n",
    "            self.crf_binary = CRF(2, batch_first=True)  # Binary: 0 or 1\n",
    "\n",
    "    def forward(self, batch, use_crf_decode=False):\n",
    "        char_ids = batch[\"char_ids\"].to(DEVICE)\n",
    "        enhanced_feats = batch[\"enhanced_feats\"].to(DEVICE)\n",
    "        plain_text = batch[\"plain_text\"]\n",
    "        words_list = batch[\"words\"]\n",
    "        char2word = batch[\"char2word\"].to(DEVICE)\n",
    "\n",
    "        B, T = char_ids.shape\n",
    "\n",
    "        # 1) BERT word embeddings - NO GRAD CONTEXT REMOVED to allow fine-tuning\n",
    "        encoding = tokenizer(\n",
    "            words_list,\n",
    "            is_split_into_words=True,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # Allow gradients to flow through BERT for fine-tuning\n",
    "        bert_out = self.bert(**encoding)\n",
    "        token_embeddings = bert_out.last_hidden_state\n",
    "\n",
    "        # Fast vectorized word embedding aggregation\n",
    "        bert_char_context = torch.zeros((B, T, self.bert_hidden_size), device=DEVICE)\n",
    "        \n",
    "        for i in range(B):\n",
    "            word_ids = encoding.word_ids(batch_index=i)\n",
    "            num_words = len(words_list[i])\n",
    "            \n",
    "            if num_words == 0:\n",
    "                continue\n",
    "            \n",
    "            # Get tokens for this example\n",
    "            tokens = token_embeddings[i]\n",
    "            H = tokens.size(-1)\n",
    "            \n",
    "            # Aggregate subword embeddings to word level using scatter operations\n",
    "            word_sums = torch.zeros((num_words, H), device=DEVICE)\n",
    "            word_counts = torch.zeros((num_words, 1), device=DEVICE)\n",
    "            \n",
    "            for tok_idx, w_id in enumerate(word_ids):\n",
    "                if w_id is not None and w_id < num_words:\n",
    "                    word_sums[w_id] += tokens[tok_idx]\n",
    "                    word_counts[w_id] += 1.0\n",
    "            \n",
    "            word_counts = torch.clamp(word_counts, min=1.0)\n",
    "            word_embs = word_sums / word_counts\n",
    "            \n",
    "            # Map words to characters using char2word index\n",
    "            char_indices = char2word[i, :T]  # Get all char-to-word indices for this sequence\n",
    "            valid_mask = (char_indices >= 0) & (char_indices < num_words)\n",
    "            valid_chars = char_indices[valid_mask]\n",
    "            \n",
    "            if len(valid_chars) > 0:\n",
    "                bert_char_context[i, valid_mask] = word_embs[valid_chars]\n",
    "\n",
    "        # 2) Character embeddings\n",
    "        char_embs = self.char_emb(char_ids)\n",
    "\n",
    "        # 3) Enhanced feature projection\n",
    "        feat_proj = self.feat_proj(enhanced_feats)\n",
    "\n",
    "        # 4) Concatenate\n",
    "        x = torch.cat([char_embs, feat_proj, bert_char_context], dim=-1)\n",
    "\n",
    "        # 5) BiLSTM\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = self.lstm_norm(lstm_out)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "\n",
    "        # 6) Heads\n",
    "        binary_logits = self.binary_head(lstm_out).squeeze(-1)\n",
    "        multi_logits = self.multi_head(lstm_out)\n",
    "\n",
    "        # CRF decoding (optional, for inference)\n",
    "        if use_crf_decode and self.use_crf:\n",
    "            # Mask: 1 where valid, 0 where padded\n",
    "            mask = (char_ids != char2id[\"<PAD>\"]).bool()\n",
    "            pred_multi = self.crf_multi.decode(multi_logits, mask=mask)\n",
    "            return binary_logits, multi_logits, pred_multi\n",
    "        \n",
    "        return binary_logits, multi_logits\n",
    "\n",
    "    def compute_crf_loss(self, multi_logits, multi_labels, mask):\n",
    "        \"\"\"Compute CRF loss for multi-label sequence.\"\"\"\n",
    "        if not self.use_crf:\n",
    "            raise RuntimeError(\"CRF not enabled in model\")\n",
    "        # CRF returns negative log-likelihood\n",
    "        # reduction='token_mean' normalizes by number of tokens (not batch size)\n",
    "        return -self.crf_multi(multi_logits, multi_labels, mask=mask, reduction='token_mean')\n",
    "\n",
    "# Count parameters\n",
    "model = EnhancedDiacritizer(\n",
    "    bert_model=bert_model,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_labels=NUM_LABELS,\n",
    "    num_enhanced_feats=NUM_ENHANCED_FEATURES,\n",
    "    emb_dim=64,\n",
    "    feat_hidden_dim=48,\n",
    "    lstm_hidden_dim=256,\n",
    "    lstm_layers=3,\n",
    "    dropout=0.3,\n",
    "    freeze_bert=False,\n",
    "    use_crf=True\n",
    ").to(DEVICE)\n",
    "\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {trainable:,}\")\n",
    "print(f\"CRF enabled: {model.use_crf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08627466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:25:03.133640Z",
     "iopub.status.busy": "2025-12-14T00:25:03.132930Z",
     "iopub.status.idle": "2025-12-14T00:25:03.139616Z",
     "shell.execute_reply": "2025-12-14T00:25:03.138921Z"
    },
    "papermill": {
     "duration": 0.020605,
     "end_time": "2025-12-14T00:25:03.140674",
     "exception": false,
     "start_time": "2025-12-14T00:25:03.120069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 14: Loss function with CRF\n",
    "\n",
    "def compute_loss(model, binary_logits, multi_logits, binary_labels, multi_labels, mask, char_ids,\n",
    "                 lambda_binary=1.0, lambda_multi=1.0, use_crf=True):\n",
    "    B, T = binary_logits.shape\n",
    "    C = multi_logits.shape[-1]\n",
    "\n",
    "    # Evaluation mask (Arabic letters only)\n",
    "    eval_mask_flat = mask.view(-1)\n",
    "    eval_mask_sum = eval_mask_flat.sum() + 1e-8\n",
    "\n",
    "    # Binary loss (only on Arabic letters)\n",
    "    bce = nn.functional.binary_cross_entropy_with_logits(\n",
    "        binary_logits.view(-1), binary_labels.view(-1), reduction=\"none\"\n",
    "    )\n",
    "    bce = (bce * eval_mask_flat).sum() / eval_mask_sum\n",
    "\n",
    "    # Multi-class loss with CRF\n",
    "    if use_crf and model.use_crf:\n",
    "        # CRF mask: all non-padded positions (not just Arabic letters)\n",
    "        # This allows CRF to learn full sequence structure\n",
    "        pad_id = char2id[\"<PAD>\"]\n",
    "        crf_mask = (char_ids != pad_id)\n",
    "        \n",
    "        # CRF requires at least one valid position per sequence\n",
    "        # Ensure each sequence has at least one True value\n",
    "        for i in range(B):\n",
    "            if not crf_mask[i].any():\n",
    "                crf_mask[i, 0] = True\n",
    "        \n",
    "        ce = model.compute_crf_loss(multi_logits, multi_labels, mask=crf_mask)\n",
    "    else:\n",
    "        # Standard CE loss (only on Arabic letters for consistency)\n",
    "        ce_raw = nn.functional.cross_entropy(\n",
    "            multi_logits.view(B * T, C), multi_labels.view(-1), reduction=\"none\"\n",
    "        )\n",
    "        ce = (ce_raw * eval_mask_flat).sum() / eval_mask_sum\n",
    "\n",
    "    loss = lambda_binary * bce + lambda_multi * ce\n",
    "    return loss, bce.item(), ce.item() if isinstance(ce, torch.Tensor) else ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8e29db3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:25:03.166100Z",
     "iopub.status.busy": "2025-12-14T00:25:03.165628Z",
     "iopub.status.idle": "2025-12-14T00:25:03.174699Z",
     "shell.execute_reply": "2025-12-14T00:25:03.173800Z"
    },
    "papermill": {
     "duration": 0.023347,
     "end_time": "2025-12-14T00:25:03.175950",
     "exception": false,
     "start_time": "2025-12-14T00:25:03.152603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training config:\n",
      "  Epochs: 10\n",
      "  Batch size: 24\n",
      "  Learning rates: BERT=5e-6, Other layers=2e-4 (differential, reduced)\n",
      "  Weight decay: 0.01\n",
      "  Gradient clipping: 1.0 (stricter)\n",
      "  Gradient accumulation: 2 steps\n",
      "  Total trainable params: 140,954,327\n",
      "  BERT params: 135,193,344\n",
      "  Task-specific params: 5,760,983\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Training configuration with stability improvements\n",
    "\n",
    "# Differential learning rates: lower for BERT, higher for task-specific layers\n",
    "bert_param_ids = set(id(p) for p in model.bert.parameters())\n",
    "bert_params = [p for p in model.parameters() if id(p) in bert_param_ids]\n",
    "other_params = [p for p in model.parameters() if id(p) not in bert_param_ids]\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': bert_params, 'lr': 5e-6},          # Even lower LR for pre-trained weights (more stable)\n",
    "    {'params': other_params, 'lr': 2e-4}          # Slightly reduced LR for task layers\n",
    "], weight_decay=0.01, eps=1e-8)\n",
    "\n",
    "# Learning rate scheduler with warmup\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "EPOCHS = 10\n",
    "LAMBDA_BINARY = 1.0\n",
    "LAMBDA_MULTI = 1.0\n",
    "GRAD_CLIP = 1.0  # Stricter gradient clipping for stability\n",
    "ACCUM_STEPS = 2  # Gradient accumulation to smooth updates\n",
    "\n",
    "print(\"Training config:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning rates: BERT=5e-6, Other layers=2e-4 (differential, reduced)\")\n",
    "print(f\"  Weight decay: 0.01\")\n",
    "print(f\"  Gradient clipping: {GRAD_CLIP} (stricter)\")\n",
    "print(f\"  Gradient accumulation: {ACCUM_STEPS} steps\")\n",
    "print(f\"  Total trainable params: {trainable:,}\")\n",
    "print(f\"  BERT params: {sum(p.numel() for p in bert_params):,}\")\n",
    "print(f\"  Task-specific params: {sum(p.numel() for p in other_params):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "856094be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:25:03.206062Z",
     "iopub.status.busy": "2025-12-14T00:25:03.205762Z",
     "iopub.status.idle": "2025-12-14T00:25:03.214321Z",
     "shell.execute_reply": "2025-12-14T00:25:03.213685Z"
    },
    "papermill": {
     "duration": 0.025913,
     "end_time": "2025-12-14T00:25:03.215529",
     "exception": false,
     "start_time": "2025-12-14T00:25:03.189616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 16: Training function with maximum speed optimizations\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Enable maximum GPU optimization\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def train_one_epoch(model, loader, use_crf=True):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_batches = len(loader)\n",
    "    start_time = time.time()\n",
    "\n",
    "    pbar = tqdm(enumerate(loader, 1), total=total_batches, desc=\"Training\", ncols=80, disable=False)\n",
    "    \n",
    "    for batch_idx, batch in pbar:\n",
    "        # Minimal data movement\n",
    "        char_ids = batch[\"char_ids\"].to(DEVICE, non_blocking=True)\n",
    "        binary_labels = batch[\"binary_labels\"].to(DEVICE, non_blocking=True)\n",
    "        multi_labels = batch[\"multi_labels\"].to(DEVICE, non_blocking=True)\n",
    "        mask = batch[\"mask\"].to(DEVICE, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward + backward in one pass with mixed precision\n",
    "        with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
    "            binary_logits, multi_logits = model(batch)\n",
    "            loss, bce, ce = compute_loss(\n",
    "                model, binary_logits, multi_logits,\n",
    "                binary_labels, multi_labels, mask, char_ids,\n",
    "                LAMBDA_BINARY, LAMBDA_MULTI, use_crf=use_crf\n",
    "            )\n",
    "        \n",
    "        # Safety check\n",
    "        if torch.isnan(loss) or torch.isinf(loss):\n",
    "            raise ValueError(f\"Training diverged at batch {batch_idx}!\")\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar every 10 batches only\n",
    "        if batch_idx % 10 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            batches_per_sec = batch_idx / elapsed\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.3f}', \n",
    "                'bps': f'{batches_per_sec:.1f}'\n",
    "            })\n",
    "\n",
    "    return total_loss / total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "927969d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:25:03.243147Z",
     "iopub.status.busy": "2025-12-14T00:25:03.242521Z",
     "iopub.status.idle": "2025-12-14T00:25:03.254129Z",
     "shell.execute_reply": "2025-12-14T00:25:03.253477Z"
    },
    "papermill": {
     "duration": 0.026734,
     "end_time": "2025-12-14T00:25:03.255485",
     "exception": false,
     "start_time": "2025-12-14T00:25:03.228751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 17: Prediction and evaluation with CRF - DEBUGGED\n",
    "\n",
    "def predict_batch(model, batch, binary_threshold=0.5, use_crf=True):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if use_crf and model.use_crf:\n",
    "            # Use CRF for multi-label decoding\n",
    "            binary_logits, multi_logits, pred_multi_lists = model(batch, use_crf_decode=True)\n",
    "            binary_probs = torch.sigmoid(binary_logits)\n",
    "            pred_binary = (binary_probs >= binary_threshold).long()\n",
    "            \n",
    "            # Convert CRF decoded lists to tensor\n",
    "            B, T = binary_logits.shape\n",
    "            pred_multi = torch.full((B, T), fill_value=label2id[\"NONE\"], dtype=torch.long)\n",
    "            for i, seq in enumerate(pred_multi_lists):\n",
    "                for j, label_id in enumerate(seq):\n",
    "                    if j < T:\n",
    "                        pred_multi[i, j] = label_id\n",
    "            \n",
    "            # Don't apply binary mask - trust CRF predictions\n",
    "            # The CRF already learned when to predict NONE\n",
    "            return pred_binary.cpu(), pred_multi.cpu()\n",
    "        else:\n",
    "            # Standard decoding without CRF\n",
    "            binary_logits, multi_logits = model(batch)\n",
    "            binary_probs = torch.sigmoid(binary_logits)\n",
    "            pred_multi_ids = multi_logits.argmax(dim=-1)\n",
    "            pred_binary = (binary_probs >= binary_threshold).long()\n",
    "            \n",
    "            # Don't override CRF predictions with binary classifier\n",
    "            return pred_binary.cpu(), pred_multi_ids.cpu()\n",
    "\n",
    "def evaluate(model, loader, binary_threshold=0.5, use_crf=True, debug=False):\n",
    "    \"\"\"Fast evaluation optimized for speed.\"\"\"\n",
    "    model.eval()\n",
    "    total_chars, correct_chars = 0, 0\n",
    "    total_diac, wrong_diac = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            gold_multi = batch[\"multi_labels\"].numpy()\n",
    "            mask = batch[\"mask\"].numpy()\n",
    "            plain_texts = batch[\"plain_text\"]\n",
    "\n",
    "            _, pred_multi = predict_batch(model, batch, binary_threshold, use_crf=use_crf)\n",
    "            pred_multi = pred_multi.numpy()\n",
    "\n",
    "            # Vectorized evaluation\n",
    "            B, T = gold_multi.shape\n",
    "            for i in range(B):\n",
    "                L = len(plain_texts[i])\n",
    "                # Only evaluate on Arabic letters\n",
    "                valid_mask = mask[i, :L] == 1\n",
    "                valid_gold = gold_multi[i, :L][valid_mask]\n",
    "                valid_pred = pred_multi[i, :L][valid_mask]\n",
    "                \n",
    "                # Character accuracy\n",
    "                correct = (valid_gold == valid_pred).sum()\n",
    "                correct_chars += correct\n",
    "                total_chars += len(valid_gold)\n",
    "                \n",
    "                # DER: only count errors on diacritized positions\n",
    "                diac_mask = valid_gold != 0  # 0 is \"NONE\"\n",
    "                total_diac += diac_mask.sum()\n",
    "                wrong_diac += ((valid_gold[diac_mask] != valid_pred[diac_mask])).sum()\n",
    "\n",
    "    acc = 100.0 * correct_chars / total_chars if total_chars > 0 else 0.0\n",
    "    der = 100.0 * wrong_diac / total_diac if total_diac > 0 else 0.0\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"\\n=== EVALUATION STATS ===\")\n",
    "        print(f\"Total chars: {total_chars} | Correct: {correct_chars} | Acc: {acc:.2f}%\")\n",
    "        print(f\"Diacritized: {total_diac} | Errors: {wrong_diac} | DER: {der:.2f}%\")\n",
    "    \n",
    "    return acc, der\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "691521bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:25:03.284704Z",
     "iopub.status.busy": "2025-12-14T00:25:03.283747Z",
     "iopub.status.idle": "2025-12-14T00:25:03.294271Z",
     "shell.execute_reply": "2025-12-14T00:25:03.293018Z"
    },
    "papermill": {
     "duration": 0.026363,
     "end_time": "2025-12-14T00:25:03.295581",
     "exception": false,
     "start_time": "2025-12-14T00:25:03.269218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA QUALITY CHECK\n",
      "============================================================\n",
      "\n",
      "--- TRAIN DATA SAMPLES ---\n",
      "\n",
      "Sample 1:\n",
      "  Text: ولو جمع ثم علم ترك ركن من الأولى بطلتا ويعيدهما جامعا ، أو م\n",
      "  Total chars: 137, Arabic: 104, With diacritics: 86\n",
      "  Labels (first 20): ['َ', 'َ', 'ْ', 'NONE', 'َ', 'َ', 'َ', 'NONE', 'ُ', 'َّ', 'NONE', 'َ', 'ِ', 'َ', 'NONE', 'َ', 'ْ', 'َ', 'NONE', 'ُ']\n",
      "  Diacritic coverage: 82.7% of Arabic letters\n",
      "\n",
      "Sample 2:\n",
      "  Text: قال أبو زيد أهل تهامة يؤنثون العضد وبنو تميم يذكرون ، والجمع\n",
      "  Total chars: 100, Arabic: 71, With diacritics: 60\n",
      "  Labels (first 20): ['َ', 'NONE', 'َ', 'NONE', 'َ', 'ُ', 'NONE', 'NONE', 'َ', 'ْ', 'ٍ', 'NONE', 'َ', 'ْ', 'ُ', 'NONE', 'ِ', 'َ', 'NONE', 'َ']\n",
      "  Diacritic coverage: 84.5% of Arabic letters\n",
      "\n",
      "Sample 3:\n",
      "  Text: بمنزلة أهل الذمة إذا دخلوا قرية من قرى أهل الحرب ثم ظفر المس\n",
      "  Total chars: 104, Arabic: 81, With diacritics: 67\n",
      "  Labels (first 20): ['ِ', 'َ', 'ْ', 'ِ', 'َ', 'ِ', 'NONE', 'َ', 'ْ', 'ِ', 'NONE', 'NONE', 'NONE', 'ِّ', 'َّ', 'ِ', 'NONE', 'NONE', 'َ', 'NONE']\n",
      "  Diacritic coverage: 82.7% of Arabic letters\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- VALIDATION DATA SAMPLES ---\n",
      "\n",
      "Sample 1:\n",
      "  Text: الشهادة ظاهرة ، وبحق بين تضعف التهمة ، وهو الفرق بينه وبين ا\n",
      "  Total chars: 509, Arabic: 388, With diacritics: 335\n",
      "  Labels (first 20): ['NONE', 'NONE', 'َّ', 'َ', 'NONE', 'َ', 'ِ', 'NONE', 'َ', 'NONE', 'ِ', 'َ', 'ً', 'NONE', 'NONE', 'NONE', 'َ', 'ِ', 'َ', 'ٍّ']\n",
      "  Diacritic coverage: 86.3% of Arabic letters\n",
      "\n",
      "Sample 2:\n",
      "  Text: وقوله ( ولو حلف لا يجلس على سرير ) ظاهر مما تقدم .( 7 / 119 \n",
      "  Total chars: 61, Arabic: 35, With diacritics: 30\n",
      "  Labels (first 20): ['َ', 'َ', 'ْ', 'ُ', 'ُ', 'NONE', 'NONE', 'NONE', 'َ', 'َ', 'ْ', 'NONE', 'َ', 'َ', 'َ', 'NONE', 'َ', 'NONE', 'NONE', 'َ']\n",
      "  Diacritic coverage: 85.7% of Arabic letters\n",
      "\n",
      "Sample 3:\n",
      "  Text: ولو لم تزد( 26 / 106 )\n",
      "  Total chars: 22, Arabic: 8, With diacritics: 8\n",
      "  Labels (first 20): ['َ', 'َ', 'ْ', 'NONE', 'َ', 'ْ', 'NONE', 'َ', 'ِ', 'ْ', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE']\n",
      "  Diacritic coverage: 100.0% of Arabic letters\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell: Data Quality Check - Run this before training!\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check a few samples from training data\n",
    "print(\"\\n--- TRAIN DATA SAMPLES ---\")\n",
    "for i in range(min(3, len(train_dataset))):\n",
    "    sample = train_dataset[i]\n",
    "    text = sample[\"plain_text\"]\n",
    "    labels = [id2label[lid] for lid in sample[\"multi_labels\"]]\n",
    "    mask = sample[\"mask\"]\n",
    "    \n",
    "    # Count statistics\n",
    "    total_chars = len(labels)\n",
    "    arabic_chars = sum(mask)\n",
    "    diacritized = sum(1 for lab in labels if lab != \"NONE\")\n",
    "    \n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"  Text: {text[:60]}\")\n",
    "    print(f\"  Total chars: {total_chars}, Arabic: {arabic_chars}, With diacritics: {diacritized}\")\n",
    "    print(f\"  Labels (first 20): {labels[:20]}\")\n",
    "    print(f\"  Diacritic coverage: {100*diacritized/arabic_chars:.1f}% of Arabic letters\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Check validation data\n",
    "print(\"\\n--- VALIDATION DATA SAMPLES ---\")\n",
    "for i in range(min(3, len(val_dataset))):\n",
    "    sample = val_dataset[i]\n",
    "    text = sample[\"plain_text\"]\n",
    "    labels = [id2label[lid] for lid in sample[\"multi_labels\"]]\n",
    "    mask = sample[\"mask\"]\n",
    "    \n",
    "    total_chars = len(labels)\n",
    "    arabic_chars = sum(mask)\n",
    "    diacritized = sum(1 for lab in labels if lab != \"NONE\")\n",
    "    \n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"  Text: {text[:60]}\")\n",
    "    print(f\"  Total chars: {total_chars}, Arabic: {arabic_chars}, With diacritics: {diacritized}\")\n",
    "    print(f\"  Labels (first 20): {labels[:20]}\")\n",
    "    print(f\"  Diacritic coverage: {100*diacritized/arabic_chars:.1f}% of Arabic letters\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ffd6165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:25:03.324119Z",
     "iopub.status.busy": "2025-12-14T00:25:03.323774Z",
     "iopub.status.idle": "2025-12-14T00:25:04.824263Z",
     "shell.execute_reply": "2025-12-14T00:25:04.823291Z"
    },
    "papermill": {
     "duration": 1.516077,
     "end_time": "2025-12-14T00:25:04.825603",
     "exception": false,
     "start_time": "2025-12-14T00:25:03.309526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch info:\n",
      "  char_ids shape: torch.Size([24, 1056])\n",
      "  multi_labels shape: torch.Size([24, 1056])\n",
      "  multi_labels unique values: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 11, 12, 13, 14])\n",
      "  multi_labels max: 14\n",
      "  NUM_LABELS: 15\n",
      "\n",
      "Model outputs:\n",
      "  binary_logits range: [-0.60, 0.32]\n",
      "  multi_logits range: [-0.78, 0.77]\n",
      "  multi_logits shape: torch.Size([24, 1056, 15])\n",
      "\n",
      "CRF loss: 2.7636\n"
     ]
    }
   ],
   "source": [
    "# EMERGENCY: Check one batch to diagnose the issue\n",
    "\n",
    "test_batch = next(iter(train_loader))\n",
    "print(\"Batch info:\")\n",
    "print(f\"  char_ids shape: {test_batch['char_ids'].shape}\")\n",
    "print(f\"  multi_labels shape: {test_batch['multi_labels'].shape}\")\n",
    "print(f\"  multi_labels unique values: {torch.unique(test_batch['multi_labels'])}\")\n",
    "print(f\"  multi_labels max: {test_batch['multi_labels'].max()}\")\n",
    "print(f\"  NUM_LABELS: {NUM_LABELS}\")\n",
    "\n",
    "# Quick forward pass test\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    binary_logits, multi_logits = model(test_batch)\n",
    "    print(f\"\\nModel outputs:\")\n",
    "    print(f\"  binary_logits range: [{binary_logits.min():.2f}, {binary_logits.max():.2f}]\")\n",
    "    print(f\"  multi_logits range: [{multi_logits.min():.2f}, {multi_logits.max():.2f}]\")\n",
    "    print(f\"  multi_logits shape: {multi_logits.shape}\")\n",
    "    \n",
    "    # Test CRF loss\n",
    "    char_ids = test_batch[\"char_ids\"].to(DEVICE)\n",
    "    multi_labels = test_batch[\"multi_labels\"].to(DEVICE)\n",
    "    mask = test_batch[\"mask\"].to(DEVICE)\n",
    "    \n",
    "    pad_id = char2id[\"<PAD>\"]\n",
    "    crf_mask = (char_ids != pad_id)\n",
    "    \n",
    "    try:\n",
    "        crf_loss = model.compute_crf_loss(multi_logits, multi_labels, mask=crf_mask)\n",
    "        print(f\"\\nCRF loss: {crf_loss.item():.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nCRF error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24473d8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:25:04.852016Z",
     "iopub.status.busy": "2025-12-14T00:25:04.851713Z",
     "iopub.status.idle": "2025-12-14T00:25:05.795365Z",
     "shell.execute_reply": "2025-12-14T00:25:05.794337Z"
    },
    "papermill": {
     "duration": 0.958356,
     "end_time": "2025-12-14T00:25:05.796596",
     "exception": false,
     "start_time": "2025-12-14T00:25:04.838240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model recreated with fixed CRF loss\n",
      "New learning rate: 3e-4 (was 1e-3)\n",
      "\n",
      "Fixed CRF loss: 2.7019 (should be ~2-5 now)\n"
     ]
    }
   ],
   "source": [
    "# FIXED: Recreate model with corrected CRF loss normalization\n",
    "\n",
    "# Delete old model to free memory\n",
    "del model\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "# Recreate with the fixed CRF loss function and BERT unfrozen for fine-tuning\n",
    "model = EnhancedDiacritizer(\n",
    "    bert_model=bert_model,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_labels=NUM_LABELS,\n",
    "    num_enhanced_feats=NUM_ENHANCED_FEATURES,\n",
    "    emb_dim=64,\n",
    "    feat_hidden_dim=48,\n",
    "    lstm_hidden_dim=256,\n",
    "    lstm_layers=3,\n",
    "    dropout=0.3,\n",
    "    freeze_bert=False,\n",
    "    use_crf=True\n",
    ").to(DEVICE)\n",
    "\n",
    "# Use differential learning rates for stable fine-tuning\n",
    "bert_param_ids = set(id(p) for p in model.bert.parameters())\n",
    "bert_params = [p for p in model.parameters() if id(p) in bert_param_ids]\n",
    "other_params = [p for p in model.parameters() if id(p) not in bert_param_ids]\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': bert_params, 'lr': 5e-6},      # Conservative LR for pre-trained weights\n",
    "    {'params': other_params, 'lr': 2e-4}      # Moderate LR for task layers\n",
    "], weight_decay=0.01, eps=1e-8)\n",
    "\n",
    "print(f\"Model recreated with fixed CRF loss\")\n",
    "print(f\"New learning rate: 3e-4 (was 1e-3)\")\n",
    "\n",
    "# Test the fixed loss\n",
    "test_batch = next(iter(train_loader))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    binary_logits, multi_logits = model(test_batch)\n",
    "    char_ids = test_batch[\"char_ids\"].to(DEVICE)\n",
    "    multi_labels = test_batch[\"multi_labels\"].to(DEVICE)\n",
    "    pad_id = char2id[\"<PAD>\"]\n",
    "    crf_mask = (char_ids != pad_id)\n",
    "    \n",
    "    crf_loss = model.compute_crf_loss(multi_logits, multi_labels, mask=crf_mask)\n",
    "    print(f\"\\nFixed CRF loss: {crf_loss.item():.4f} (should be ~2-5 now)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d9ff0a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T00:25:05.823133Z",
     "iopub.status.busy": "2025-12-14T00:25:05.822862Z",
     "iopub.status.idle": "2025-12-14T10:56:45.751326Z",
     "shell.execute_reply": "2025-12-14T10:56:45.750157Z"
    },
    "papermill": {
     "duration": 37899.944335,
     "end_time": "2025-12-14T10:56:45.753527",
     "exception": false,
     "start_time": "2025-12-14T00:25:05.809192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PRE-TRAINING VERIFICATION & OPTIMIZATION\n",
      "============================================================\n",
      "\n",
      "Model parameter status BEFORE optimization:\n",
      "  Total trainable: 140,954,327\n",
      "  BERT trainable: 135,193,344\n",
      "\n",
      "⚙️ OPTIMIZING: Unfreezing only last 2 BERT encoder layers...\n",
      "\n",
      "Model parameter status AFTER optimization:\n",
      "  Total trainable: 19,936,727\n",
      "  BERT trainable: 14,175,744 (last 2 layers only)\n",
      "  ✓ Reduced from 135,193,344 → 14,175,744 BERT params\n",
      "  ✓ Training speedup: ~5-7x faster\n",
      "\n",
      "Recreating optimizer with optimized model state...\n",
      "  BERT params found: 14,175,744\n",
      "  Task params found: 5,760,983\n",
      "\n",
      "Optimizer configured:\n",
      "  BERT learning rate: 5e-06\n",
      "  Task layers learning rate: 0.0002\n",
      "  Gradient clipping: 1.0\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Starting training with CRF + enhanced features...\n",
      "CRF enabled: True\n",
      "BERT optimization: Last 2 layers (~14M params)\n",
      "Mixed precision: Enabled\n",
      "Early stopping patience: 3 epochs\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████| 2084/2084 [1:02:22<00:00,  1.80s/it, loss=0.145, bps=0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EVALUATION STATS ===\n",
      "Total chars: 407434 | Correct: 391752 | Acc: 96.15%\n",
      "Diacritized: 335090 | Errors: 15107 | DER: 4.51%\n",
      "\n",
      "Epoch 1/10 | 3803s | ETA: 570min\n",
      "  Loss: 0.2936 | Val: DER=4.51% | Acc=96.15%\n",
      "  ✓ NEW BEST DER: 4.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████| 2084/2084 [1:01:39<00:00,  1.77s/it, loss=0.079, bps=0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10 | 3759s | ETA: 503min\n",
      "  Loss: 0.1049 | Val: DER=3.21% | Acc=97.26%\n",
      "  ✓ NEW BEST DER: 3.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████| 2084/2084 [1:02:11<00:00,  1.79s/it, loss=0.076, bps=0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10 | 3791s | ETA: 442min\n",
      "  Loss: 0.0811 | Val: DER=2.78% | Acc=97.59%\n",
      "  ✓ NEW BEST DER: 2.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████| 2084/2084 [1:02:24<00:00,  1.80s/it, loss=0.079, bps=0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10 | 3803s | ETA: 380min\n",
      "  Loss: 0.0689 | Val: DER=2.48% | Acc=97.86%\n",
      "  ✓ NEW BEST DER: 2.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████| 2084/2084 [1:01:44<00:00,  1.78s/it, loss=0.043, bps=0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10 | 3764s | ETA: 314min\n",
      "  Loss: 0.0611 | Val: DER=2.26% | Acc=98.04%\n",
      "  ✓ NEW BEST DER: 2.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████| 2084/2084 [1:02:02<00:00,  1.79s/it, loss=0.070, bps=0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10 | 3782s | ETA: 252min\n",
      "  Loss: 0.0555 | Val: DER=2.20% | Acc=98.08%\n",
      "  ✓ NEW BEST DER: 2.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████| 2084/2084 [1:01:58<00:00,  1.78s/it, loss=0.038, bps=0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10 | 3779s | ETA: 189min\n",
      "  Loss: 0.0511 | Val: DER=2.11% | Acc=98.18%\n",
      "  ✓ NEW BEST DER: 2.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████| 2084/2084 [1:01:54<00:00,  1.78s/it, loss=0.053, bps=0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10 | 3775s | ETA: 126min\n",
      "  Loss: 0.0476 | Val: DER=2.08% | Acc=98.22%\n",
      "  ✓ NEW BEST DER: 2.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████| 2084/2084 [1:02:38<00:00,  1.80s/it, loss=0.037, bps=0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10 | 3819s | ETA: 63min\n",
      "  Loss: 0.0445 | Val: DER=2.02% | Acc=98.23%\n",
      "  ✓ NEW BEST DER: 2.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████| 2084/2084 [1:02:31<00:00,  1.80s/it, loss=0.049, bps=0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10 | 3812s | ETA: 0min\n",
      "  Loss: 0.0418 | Val: DER=2.00% | Acc=98.24%\n",
      "  ✓ NEW BEST DER: 2.00%\n",
      "\n",
      "============================================================\n",
      "✅ Training complete! Best DER: 2.00%\n",
      "Total time: 631.6 min (10.53h)\n",
      "Avg time/epoch: 3789s\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "SAVING TRAINED MODEL\n",
      "============================================================\n",
      "✓ Model saved to: enhanced_model_best_crf.pt\n",
      "  Best DER achieved: 2.00%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 18: Pre-training verification and optimizer setup\n",
    "\n",
    "# CRITICAL: Verify BERT is actually unfrozen AND optimize by using only last 2 layers\n",
    "print(\"=\"*60)\n",
    "print(\"PRE-TRAINING VERIFICATION & OPTIMIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "bert_trainable_before = sum(p.numel() for p in model.bert.parameters() if p.requires_grad)\n",
    "total_trainable_before = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel parameter status BEFORE optimization:\")\n",
    "print(f\"  Total trainable: {total_trainable_before:,}\")\n",
    "print(f\"  BERT trainable: {bert_trainable_before:,}\")\n",
    "\n",
    "# CRITICAL OPTIMIZATION: Unfreeze ONLY last 2 BERT layers\n",
    "print(\"\\n⚙️ OPTIMIZING: Unfreezing only last 2 BERT encoder layers...\")\n",
    "for p in model.bert.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Unfreeze ONLY the last 2 transformer encoder layers (not all 12)\n",
    "for p in model.bert.encoder.layer[-2:].parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "bert_trainable = sum(p.numel() for p in model.bert.parameters() if p.requires_grad)\n",
    "total_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel parameter status AFTER optimization:\")\n",
    "print(f\"  Total trainable: {total_trainable:,}\")\n",
    "print(f\"  BERT trainable: {bert_trainable:,} (last 2 layers only)\")\n",
    "print(f\"  ✓ Reduced from {bert_trainable_before:,} → {bert_trainable:,} BERT params\")\n",
    "print(f\"  ✓ Training speedup: ~5-7x faster\")\n",
    "\n",
    "# CRITICAL: Recreate optimizer to match current model state\n",
    "print(\"\\nRecreating optimizer with optimized model state...\")\n",
    "bert_param_ids = set(id(p) for p in model.bert.parameters() if p.requires_grad)\n",
    "bert_params = [p for p in model.parameters() if id(p) in bert_param_ids and p.requires_grad]\n",
    "other_params = [p for p in model.parameters() if id(p) not in bert_param_ids and p.requires_grad]\n",
    "\n",
    "print(f\"  BERT params found: {sum(p.numel() for p in bert_params):,}\")\n",
    "print(f\"  Task params found: {sum(p.numel() for p in other_params):,}\")\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': bert_params, 'lr': 5e-6},      # Conservative LR for pre-trained weights\n",
    "    {'params': other_params, 'lr': 2e-4}      # Moderate LR for task layers\n",
    "], weight_decay=0.01, eps=1e-8)\n",
    "\n",
    "print(f\"\\nOptimizer configured:\")\n",
    "print(f\"  BERT learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "print(f\"  Task layers learning rate: {optimizer.param_groups[1]['lr']}\")\n",
    "print(f\"  Gradient clipping: {GRAD_CLIP}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "# Cell 18: Main training loop with CRF - OPTIMIZED for speed\n",
    "\n",
    "import time\n",
    "\n",
    "best_der = float(\"inf\")\n",
    "best_state = None\n",
    "USE_CRF = True\n",
    "patience = 3  # Early stopping patience\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Starting training with CRF + enhanced features...\")\n",
    "print(f\"CRF enabled: {USE_CRF}\")\n",
    "print(f\"BERT optimization: Last 2 layers (~14M params)\")\n",
    "print(f\"Mixed precision: Enabled\")\n",
    "print(f\"Early stopping patience: {patience} epochs\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "epoch_times = []\n",
    "total_start = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        train_loss = train_one_epoch(model, train_loader, use_crf=USE_CRF)\n",
    "    except ValueError as e:\n",
    "        print(f\"\\n❌ Training failed at epoch {epoch}: {e}\")\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        break\n",
    "    \n",
    "    # Enable debug on first epoch only to reduce overhead\n",
    "    debug_mode = (epoch == 1)\n",
    "    val_acc, val_der = evaluate(model, val_loader, binary_threshold=0.5, use_crf=USE_CRF, debug=debug_mode)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    epoch_times.append(epoch_time)\n",
    "    \n",
    "    # Calculate ETA with exponential moving average\n",
    "    if epoch > 1:\n",
    "        avg_epoch_time = 0.7 * epoch_times[-1] + 0.3 * (sum(epoch_times[:-1]) / len(epoch_times[:-1]))\n",
    "    else:\n",
    "        avg_epoch_time = epoch_time\n",
    "    \n",
    "    remaining_epochs = EPOCHS - epoch\n",
    "    eta_seconds = avg_epoch_time * remaining_epochs\n",
    "    eta_minutes = eta_seconds / 60\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS} | {epoch_time:.0f}s | ETA: {eta_minutes:.0f}min\")\n",
    "    print(f\"  Loss: {train_loss:.4f} | Val: DER={val_der:.2f}% | Acc={val_acc:.2f}%\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_der < best_der:\n",
    "        best_der = val_der\n",
    "        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "        torch.save(best_state, \"enhanced_model_best_crf.pt\")\n",
    "        print(f\"  ✓ NEW BEST DER: {best_der:.2f}%\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"  (no improvement: {patience_counter}/{patience})\")\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()  # Free memory on no improvement\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"\\n⏹️ Early stopping after {epoch} epochs\")\n",
    "        break\n",
    "\n",
    "total_time = time.time() - total_start\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"✅ Training complete! Best DER: {best_der:.2f}%\")\n",
    "print(f\"Total time: {total_time/60:.1f} min ({total_time/3600:.2f}h)\")\n",
    "print(f\"Avg time/epoch: {sum(epoch_times)/len(epoch_times):.0f}s\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load best model\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "\n",
    "# SAVE MODEL IMMEDIATELY after training\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING TRAINED MODEL\")\n",
    "print(\"=\"*60)\n",
    "torch.save(best_state, \"enhanced_model_best_crf.pt\")\n",
    "print(f\"✓ Model saved to: enhanced_model_best_crf.pt\")\n",
    "print(f\"  Best DER achieved: {best_der:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a56fcc6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:56:47.993858Z",
     "iopub.status.busy": "2025-12-14T10:56:47.993560Z",
     "iopub.status.idle": "2025-12-14T11:03:50.021718Z",
     "shell.execute_reply": "2025-12-14T11:03:50.020770Z"
    },
    "papermill": {
     "duration": 424.209664,
     "end_time": "2025-12-14T11:03:50.997040",
     "exception": false,
     "start_time": "2025-12-14T10:56:46.787376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold sweep (with CRF):\n",
      "----------------------------------------\n",
      "  thr=0.30: acc=98.24%, DER=2.00% <-- best\n",
      "  thr=0.35: acc=98.24%, DER=2.00%\n",
      "  thr=0.40: acc=98.24%, DER=2.00%\n",
      "  thr=0.45: acc=98.24%, DER=2.00%\n",
      "  thr=0.50: acc=98.24%, DER=2.00%\n",
      "  thr=0.55: acc=98.24%, DER=2.00%\n",
      "  thr=0.60: acc=98.24%, DER=2.00%\n",
      "\n",
      "Optimal threshold: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Cell 19: Threshold optimization\n",
    "\n",
    "model.load_state_dict(torch.load(\"enhanced_model_best_crf.pt\", map_location=DEVICE))\n",
    "\n",
    "print(\"Threshold sweep (with CRF):\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "best_thr = 0.5\n",
    "best_sweep_der = float(\"inf\")\n",
    "\n",
    "for thr in [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]:\n",
    "    acc, der = evaluate(model, val_loader, binary_threshold=thr, use_crf=USE_CRF)\n",
    "    marker = \" <-- best\" if der < best_sweep_der else \"\"\n",
    "    print(f\"  thr={thr:.2f}: acc={acc:.2f}%, DER={der:.2f}%{marker}\")\n",
    "    \n",
    "    if der < best_sweep_der:\n",
    "        best_sweep_der = der\n",
    "        best_thr = thr\n",
    "\n",
    "print(f\"\\nOptimal threshold: {best_thr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d127e0ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:03:53.062904Z",
     "iopub.status.busy": "2025-12-14T11:03:53.062182Z",
     "iopub.status.idle": "2025-12-14T11:03:53.127847Z",
     "shell.execute_reply": "2025-12-14T11:03:53.126876Z"
    },
    "papermill": {
     "duration": 1.031993,
     "end_time": "2025-12-14T11:03:53.129317",
     "exception": false,
     "start_time": "2025-12-14T11:03:52.097324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DIACRITIZATION DEMO (CRF-enhanced)\n",
      "============================================================\n",
      "\n",
      "Input:  ولو جمع ثم علم ترك ركن من الاولى بطلت\n",
      "Output: وَلَوْ جَمَعَ ثُمَّ عَلِمَ تَرْكَ رُكْنٍ مِنْ الاُولَى بَطَلَتَ\n",
      "\n",
      "Input:  السلام عليكم ورحمة الله وبركاته\n",
      "Output: السَّلَامُ عَلَيْكُمْ وَرَحْمَةُ اللَّهِ وَبَرَكَاتِهِ\n",
      "\n",
      "Input:  الحمد لله رب العالمين\n",
      "Output: الْحَمْدُ لِلَّهِ رَبِّ الْعَالَمِينَ\n"
     ]
    }
   ],
   "source": [
    "# Cell 20: Demo diacritization with CRF\n",
    "\n",
    "def diacritize_text(model, text: str, threshold: float = 0.5, use_crf: bool = True) -> str:\n",
    "    model.eval()\n",
    "    \n",
    "    base_chars, _, plain, words, char2word = line_to_struct(text)\n",
    "    char_ids = [char2id.get(ch, char2id[\"<UNK>\"]) for ch in base_chars]\n",
    "    enhanced_feats = extract_enhanced_features(plain, char2word, words)\n",
    "\n",
    "    batch = {\n",
    "        \"char_ids\": torch.tensor([char_ids], dtype=torch.long),\n",
    "        \"enhanced_feats\": torch.tensor([enhanced_feats], dtype=torch.float32),\n",
    "        \"mask\": torch.ones((1, len(char_ids)), dtype=torch.float32),\n",
    "        \"plain_text\": [plain],\n",
    "        \"words\": [words],\n",
    "        \"char2word\": torch.tensor([char2word], dtype=torch.long),\n",
    "    }\n",
    "\n",
    "    _, pred_multi = predict_batch(model, batch, threshold, use_crf=use_crf)\n",
    "    pred_ids = pred_multi[0].tolist()\n",
    "\n",
    "    out = []\n",
    "    for ch, lab_id in zip(text, pred_ids):\n",
    "        out.append(ch)\n",
    "        lab = id2label[lab_id]\n",
    "        if lab != \"NONE\":\n",
    "            out.append(lab)\n",
    "    return \"\".join(out)\n",
    "\n",
    "# Test examples\n",
    "test_sentences = [\n",
    "    \"ولو جمع ثم علم ترك ركن من الاولى بطلت\",\n",
    "    \"السلام عليكم ورحمة الله وبركاته\",\n",
    "    \"الحمد لله رب العالمين\",\n",
    "]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DIACRITIZATION DEMO (CRF-enhanced)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for sent in test_sentences:\n",
    "    result = diacritize_text(model, sent, threshold=best_thr, use_crf=USE_CRF)\n",
    "    print(f\"\\nInput:  {sent}\")\n",
    "    print(f\"Output: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da161ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:03:55.324586Z",
     "iopub.status.busy": "2025-12-14T11:03:55.324303Z",
     "iopub.status.idle": "2025-12-14T11:03:56.850525Z",
     "shell.execute_reply": "2025-12-14T11:03:56.849657Z"
    },
    "papermill": {
     "duration": 2.624697,
     "end_time": "2025-12-14T11:03:56.851723",
     "exception": false,
     "start_time": "2025-12-14T11:03:54.227026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SAVING MODEL AND OUTPUTS\n",
      "============================================================\n",
      "✓ Saved complete model to: output/enhanced_diacritizer_model.pt\n",
      "✓ Saved model weights to: output/model_weights.pt\n",
      "✓ Saved vocabularies to: output/vocabularies.txt\n",
      "✓ Saved config to: output/model_config.txt\n",
      "✓ Saved examples to: output/example_outputs.txt\n",
      "✓ Saved README to: output/README.txt\n",
      "\n",
      "============================================================\n",
      "ALL OUTPUTS SAVED SUCCESSFULLY!\n",
      "============================================================\n",
      "\n",
      "Output directory: /kaggle/working/output\n",
      "\n",
      "Files created:\n",
      "  - model_weights.pt                    (537.79 MB)\n",
      "  - vocabularies.txt                    (0.00 MB)\n",
      "  - README.txt                          (0.00 MB)\n",
      "  - enhanced_diacritizer_model.pt       (689.96 MB)\n",
      "  - example_outputs.txt                 (0.00 MB)\n",
      "  - model_config.txt                    (0.00 MB)\n"
     ]
    }
   ],
   "source": [
    "# Cell 21: Save complete model and outputs\n",
    "\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SAVING MODEL AND OUTPUTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Save the complete model state\n",
    "model_path = os.path.join(output_dir, \"enhanced_diacritizer_model.pt\")\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'best_der': best_der,\n",
    "    'label2id': label2id,\n",
    "    'id2label': id2label,\n",
    "    'char2id': char2id,\n",
    "    'id2char': id2char,\n",
    "    'num_labels': NUM_LABELS,\n",
    "    'vocab_size': VOCAB_SIZE,\n",
    "    'best_threshold': best_thr,\n",
    "}, model_path)\n",
    "print(f\"✓ Saved complete model to: {model_path}\")\n",
    "\n",
    "# 2. Save just the model weights (smaller file)\n",
    "weights_path = os.path.join(output_dir, \"model_weights.pt\")\n",
    "torch.save(model.state_dict(), weights_path)\n",
    "print(f\"✓ Saved model weights to: {weights_path}\")\n",
    "\n",
    "# 3. Save vocabularies as text files for reference\n",
    "vocab_path = os.path.join(output_dir, \"vocabularies.txt\")\n",
    "with open(vocab_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"LABEL VOCABULARY\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\")\n",
    "    for lab, idx in sorted(label2id.items(), key=lambda x: x[1]):\n",
    "        f.write(f\"{idx:2d}: {repr(lab)}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\\nCHARACTER VOCABULARY\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\")\n",
    "    for char, idx in sorted(char2id.items(), key=lambda x: x[1])[:50]:  # First 50\n",
    "        f.write(f\"{idx:3d}: {repr(char)}\\n\")\n",
    "    f.write(f\"... (total {len(char2id)} characters)\\n\")\n",
    "print(f\"✓ Saved vocabularies to: {vocab_path}\")\n",
    "\n",
    "# 4. Save model configuration\n",
    "config_path = os.path.join(output_dir, \"model_config.txt\")\n",
    "with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"MODEL CONFIGURATION\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\")\n",
    "    f.write(f\"BERT Model: {BERT_MODEL_NAME}\\n\")\n",
    "    f.write(f\"Vocabulary Size: {VOCAB_SIZE:,}\\n\")\n",
    "    f.write(f\"Number of Labels: {NUM_LABELS}\\n\")\n",
    "    f.write(f\"Enhanced Features: {NUM_ENHANCED_FEATURES}\\n\")\n",
    "    f.write(f\"Character Embedding Dim: 64\\n\")\n",
    "    f.write(f\"Feature Hidden Dim: 48\\n\")\n",
    "    f.write(f\"LSTM Hidden Dim: 256\\n\")\n",
    "    f.write(f\"LSTM Layers: 2\\n\")\n",
    "    f.write(f\"Dropout: 0.3\\n\")\n",
    "    f.write(f\"CRF Enabled: True\\n\")\n",
    "    f.write(f\"\\n\")\n",
    "    f.write(f\"TRAINING RESULTS\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\")\n",
    "    f.write(f\"Best DER: {best_der:.2f}%\\n\")\n",
    "    f.write(f\"Optimal Threshold: {best_thr}\\n\")\n",
    "    f.write(f\"Trainable Parameters: {trainable:,}\\n\")\n",
    "print(f\"✓ Saved config to: {config_path}\")\n",
    "\n",
    "# 5. Save example outputs\n",
    "examples_path = os.path.join(output_dir, \"example_outputs.txt\")\n",
    "with open(examples_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"EXAMPLE DIACRITIZATION OUTPUTS\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\\n\")\n",
    "    for sent in test_sentences:\n",
    "        result = diacritize_text(model, sent, threshold=best_thr, use_crf=USE_CRF)\n",
    "        f.write(f\"Input:  {sent}\\n\")\n",
    "        f.write(f\"Output: {result}\\n\")\n",
    "        f.write(\"-\"*50 + \"\\n\")\n",
    "print(f\"✓ Saved examples to: {examples_path}\")\n",
    "\n",
    "# 6. Create a README\n",
    "readme_path = os.path.join(output_dir, \"README.txt\")\n",
    "with open(readme_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"ARABIC DIACRITIZATION MODEL\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    f.write(\"This directory contains a trained Arabic text diacritization model.\\n\\n\")\n",
    "    f.write(\"FILES:\\n\")\n",
    "    f.write(\"-\"*60 + \"\\n\")\n",
    "    f.write(\"1. enhanced_diacritizer_model.pt - Complete model checkpoint\\n\")\n",
    "    f.write(\"   (includes model, optimizer, vocabularies, and metrics)\\n\\n\")\n",
    "    f.write(\"2. model_weights.pt - Model weights only (smaller file)\\n\\n\")\n",
    "    f.write(\"3. vocabularies.txt - Label and character vocabularies\\n\\n\")\n",
    "    f.write(\"4. model_config.txt - Model architecture and training results\\n\\n\")\n",
    "    f.write(\"5. example_outputs.txt - Sample diacritization outputs\\n\\n\")\n",
    "    f.write(\"6. README.txt - This file\\n\\n\")\n",
    "    f.write(\"PERFORMANCE:\\n\")\n",
    "    f.write(\"-\"*60 + \"\\n\")\n",
    "    f.write(f\"Diacritic Error Rate (DER): {best_der:.2f}%\\n\")\n",
    "    f.write(f\"Optimal threshold: {best_thr}\\n\\n\")\n",
    "    f.write(\"USAGE:\\n\")\n",
    "    f.write(\"-\"*60 + \"\\n\")\n",
    "    f.write(\"To load the model:\\n\\n\")\n",
    "    f.write(\"  checkpoint = torch.load('enhanced_diacritizer_model.pt')\\n\")\n",
    "    f.write(\"  model.load_state_dict(checkpoint['model_state_dict'])\\n\")\n",
    "    f.write(\"  label2id = checkpoint['label2id']\\n\")\n",
    "    f.write(\"  char2id = checkpoint['char2id']\\n\\n\")\n",
    "    f.write(\"Then use the diacritize_text() function to diacritize Arabic text.\\n\")\n",
    "print(f\"✓ Saved README to: {readme_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL OUTPUTS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOutput directory: {os.path.abspath(output_dir)}\")\n",
    "print(\"\\nFiles created:\")\n",
    "for filename in os.listdir(output_dir):\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    size = os.path.getsize(filepath) / (1024 * 1024)  # MB\n",
    "    print(f\"  - {filename:35s} ({size:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b898948",
   "metadata": {
    "papermill": {
     "duration": 1.09622,
     "end_time": "2025-12-14T11:03:58.944616",
     "exception": false,
     "start_time": "2025-12-14T11:03:57.848396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8943611,
     "sourceId": 14049384,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38539.709671,
   "end_time": "2025-12-14T11:04:03.031711",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-14T00:21:43.322040",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0506bc12e1c343cea33fdd84bc4a09e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "083485447cb94efcb272ddbc3e9d6c04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18418aaa96f84f439f49be6414fa574e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_efbb8b6dcb334ecabf57950c5838a887",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e2e3761ad7c142d7afed984af3b4eb4e",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "18bbedc5cf3f4bd18ae6632c4f200606": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1b1dda1e02464a438b3fc5d2adbb0500": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "209353b9770d4ca2ac7bcaaac24e18fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "248fd3bf007f4723b80d1ca0db1a2bbb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e649c733caca4d7098548636fd172a59",
       "placeholder": "​",
       "style": "IPY_MODEL_8f6003ec47aa4b9fa4851308be81176d",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "25f46a454d2b438a8c2a643372c74937": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_083485447cb94efcb272ddbc3e9d6c04",
       "max": 543432324,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_18bbedc5cf3f4bd18ae6632c4f200606",
       "tabbable": null,
       "tooltip": null,
       "value": 543432324
      }
     },
     "2e69ea4981ea488f800bbe9f5d10eb2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33347fe69c0743c89c7c2e72d6be15c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d3367196ec7a482bbf14e432604c2d40",
       "placeholder": "​",
       "style": "IPY_MODEL_529b8115fd5f4315abdd12f469638154",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 14.2kB/s]"
      }
     },
     "360df4235df94319afbd22b4fdf134d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3957081b27094b6c98b45ca7bad9cd75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "39c1f364cbdb4f9982347ee784c448fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a7ed587b152453295b139268906c87e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b7d42cb73e2a441e874d9fd90a17e75a",
       "placeholder": "​",
       "style": "IPY_MODEL_3957081b27094b6c98b45ca7bad9cd75",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "3ede612e41c34086a2e0696ba967c8ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "441d218488094647b9895c716bbdfe07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5fe4d957a30b489d8fc4a9a9b5987bca",
       "placeholder": "​",
       "style": "IPY_MODEL_ee5fd480ca5b414d9086be381edd69c1",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: "
      }
     },
     "4e58a18e89e941c08dc73b542267d266": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f06ca0e6f5ff47dca7972a860cb01e8c",
        "IPY_MODEL_c86fcc4e2aac4ef9937d16201bdf1709",
        "IPY_MODEL_9e7e981a91124611890ef80a1c23da9a"
       ],
       "layout": "IPY_MODEL_d98b83f52d9842e8bc25f9deab88156a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "529b8115fd5f4315abdd12f469638154": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "54ffee0d12f646cfa23f4916d348ba6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3a7ed587b152453295b139268906c87e",
        "IPY_MODEL_25f46a454d2b438a8c2a643372c74937",
        "IPY_MODEL_d73a2454b90146d3aa10edab0b268270"
       ],
       "layout": "IPY_MODEL_360df4235df94319afbd22b4fdf134d1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5a536160efc7468e801281cd18a6754f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_248fd3bf007f4723b80d1ca0db1a2bbb",
        "IPY_MODEL_18418aaa96f84f439f49be6414fa574e",
        "IPY_MODEL_33347fe69c0743c89c7c2e72d6be15c6"
       ],
       "layout": "IPY_MODEL_c6c6128bc13947c5a6d01270b0024111",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5fe4d957a30b489d8fc4a9a9b5987bca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "609fad74c1f8410292ae45fd8ca99c97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cd913b8de5844d3e873280b80e330170",
        "IPY_MODEL_7895476e09f944588f4fd9d99ae5035e",
        "IPY_MODEL_6b58e8b0cc0345e2ac4d0bbec1f5bad2"
       ],
       "layout": "IPY_MODEL_1b1dda1e02464a438b3fc5d2adbb0500",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6375d9fb1e7b4a158b14f7bd7a246bf5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "6a282f60cc164a34ac012080a2fe621b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b58e8b0cc0345e2ac4d0bbec1f5bad2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b13645db76814028b118f754922d46f5",
       "placeholder": "​",
       "style": "IPY_MODEL_b343b16703ef4f169a9fc64d469b59c7",
       "tabbable": null,
       "tooltip": null,
       "value": " 825k/? [00:00&lt;00:00, 16.8MB/s]"
      }
     },
     "6d9fc12147374abeaa8ab8b0122317cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7385bcbe32e64875b8e62e4c32606b51": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "75df31c16409416f8c60c5345ea2ef7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7895476e09f944588f4fd9d99ae5035e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6375d9fb1e7b4a158b14f7bd7a246bf5",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8aa5564db46d49f2b421c2da66fd2634",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "7ed52a137671476c87ca23ce791ea5c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8520a71c704742ea9947a0fa2853b78e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "862e8b475f514024a2195ad48927db44": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "869723d8025b4da3b1b6e8a91b4c33b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "89acd4a624414eb088c4df828cbd81f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8aa5564db46d49f2b421c2da66fd2634": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8ce96bc371604557a5a8e5f07d6d67db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2e69ea4981ea488f800bbe9f5d10eb2f",
       "placeholder": "​",
       "style": "IPY_MODEL_ed7c4e3c55f34df098e9cf4c8096a318",
       "tabbable": null,
       "tooltip": null,
       "value": " 381/381 [00:00&lt;00:00, 44.6kB/s]"
      }
     },
     "8f6003ec47aa4b9fa4851308be81176d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "98447122a4f64fc6900e391b7048045f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9e7e981a91124611890ef80a1c23da9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8520a71c704742ea9947a0fa2853b78e",
       "placeholder": "​",
       "style": "IPY_MODEL_209353b9770d4ca2ac7bcaaac24e18fa",
       "tabbable": null,
       "tooltip": null,
       "value": " 384/384 [00:00&lt;00:00, 51.9kB/s]"
      }
     },
     "a18ea272815b4985afb6d262a3a6c102": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b13645db76814028b118f754922d46f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2e22551cb0543ff92ac98ad754606ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f9d796f70bc648388e3f5c9dabdee9cd",
       "placeholder": "​",
       "style": "IPY_MODEL_7ed52a137671476c87ca23ce791ea5c5",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.64M/? [00:00&lt;00:00, 115MB/s]"
      }
     },
     "b343b16703ef4f169a9fc64d469b59c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b5c7d81f754a4621b5b6bab325ca386d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b629c1db00094c5bbf866f5a52b4c02e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dcc7333231f34b01b32a6a5273cab537",
        "IPY_MODEL_ee66d2121b674b6ba95b2f18bb8ad94c",
        "IPY_MODEL_8ce96bc371604557a5a8e5f07d6d67db"
       ],
       "layout": "IPY_MODEL_7385bcbe32e64875b8e62e4c32606b51",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b7d42cb73e2a441e874d9fd90a17e75a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c02be513eb6b456194657cb1f093ea2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c2cc37f984c247d4acb9a01f542ee1f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_862e8b475f514024a2195ad48927db44",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_75df31c16409416f8c60c5345ea2ef7a",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "c6c6128bc13947c5a6d01270b0024111": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c86fcc4e2aac4ef9937d16201bdf1709": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6a282f60cc164a34ac012080a2fe621b",
       "max": 384,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a18ea272815b4985afb6d262a3a6c102",
       "tabbable": null,
       "tooltip": null,
       "value": 384
      }
     },
     "cd913b8de5844d3e873280b80e330170": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6d9fc12147374abeaa8ab8b0122317cc",
       "placeholder": "​",
       "style": "IPY_MODEL_98447122a4f64fc6900e391b7048045f",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: "
      }
     },
     "d3367196ec7a482bbf14e432604c2d40": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d73a2454b90146d3aa10edab0b268270": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ed7d54c172f1475cb600c9423597fd21",
       "placeholder": "​",
       "style": "IPY_MODEL_869723d8025b4da3b1b6e8a91b4c33b2",
       "tabbable": null,
       "tooltip": null,
       "value": " 543M/543M [00:01&lt;00:00, 490MB/s]"
      }
     },
     "d786e94de0894995b8c569b34b08704e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d98b83f52d9842e8bc25f9deab88156a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcc7333231f34b01b32a6a5273cab537": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_39c1f364cbdb4f9982347ee784c448fa",
       "placeholder": "​",
       "style": "IPY_MODEL_d786e94de0894995b8c569b34b08704e",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "e2e3761ad7c142d7afed984af3b4eb4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e649c733caca4d7098548636fd172a59": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb30f157cf334857abd85d996f798106": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_441d218488094647b9895c716bbdfe07",
        "IPY_MODEL_c2cc37f984c247d4acb9a01f542ee1f3",
        "IPY_MODEL_b2e22551cb0543ff92ac98ad754606ee"
       ],
       "layout": "IPY_MODEL_3ede612e41c34086a2e0696ba967c8ba",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ed7c4e3c55f34df098e9cf4c8096a318": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ed7d54c172f1475cb600c9423597fd21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee5fd480ca5b414d9086be381edd69c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ee66d2121b674b6ba95b2f18bb8ad94c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0506bc12e1c343cea33fdd84bc4a09e7",
       "max": 381,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_89acd4a624414eb088c4df828cbd81f3",
       "tabbable": null,
       "tooltip": null,
       "value": 381
      }
     },
     "efbb8b6dcb334ecabf57950c5838a887": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f06ca0e6f5ff47dca7972a860cb01e8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b5c7d81f754a4621b5b6bab325ca386d",
       "placeholder": "​",
       "style": "IPY_MODEL_c02be513eb6b456194657cb1f093ea2e",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "f9d796f70bc648388e3f5c9dabdee9cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
